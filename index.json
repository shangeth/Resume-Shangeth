[{"authors":["admin"],"categories":null,"content":"I am a 3rd year Undergrad Dual degree student at BITS Pilani Goa Campus.\n","date":1558496580,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1558496580,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a 3rd year Undergrad Dual degree student at BITS Pilani Goa Campus.","tags":null,"title":"Shangeth Rajaa","type":"authors"},{"authors":null,"categories":null,"content":" Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":" Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":["Shangeth Rajaa"],"categories":["Deep Learning","Python","PyTorch"],"content":"","date":1558496580,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558496580,"objectID":"9aa73addb97c4bd545885afb2579256c","permalink":"/post/gan-4/","publishdate":"2019-05-22T03:43:00Z","relpermalink":"/post/gan-4/","section":"post","summary":"Deep Convolutional GAN","tags":["Deep Learning","GAN"],"title":"GAN 4","type":"post"},{"authors":["Shangeth Rajaa"],"categories":["Deep Learning","Python","PyTorch"],"content":" We saw an Intro to GANs and the Theory of Game between Generator and Discriminator in the previous posts. In this post we are going to implement and learn about how to train GANs in PyTorch. We will start with MNIST dataset and in the future posts we will implement different applications of GANs and also my research paper on one of the application of GANs.\nSo the task is to use the MNIST dataset to generate new MNIST alike data samples with GANs. Let\u0026rsquo;s Code GAN Get the Data Import all the necessary libraries like Numpy, Matplotlib, torch, torchvision.\nimport numpy as np import torch import matplotlib.pyplot as plt from torchvision import datasets import torchvision.transforms as transforms  Now lets get the MNIST data from the torchvision datasets.\ntransform = transforms.ToTensor() data = datasets.MNIST(root='data', train=True, download=True, transform=transform) data_loader = torch.utils.data.DataLoader(data, batch_size=1024)  The Model As we have already seen in Theory of Game between Generator and Discriminator, the GAN models generally have 2 networks Discriminator D and Generator G. We will code both of these network as seperate classes in PyTorch. Discriminator The discriminator is a just a classifier , which takes input images and classifies the images as real or fake generated images. So lets make a classifier network in PyTorch.\nimport torch.nn as nn import torch.nn.functional as F class D(nn.Module): def __init__(self, input_size, hidden_dim, output_size): super(D, self).__init__() self.fc1 = nn.Linear(input_size, hidden_dim*4) self.fc2 = nn.Linear(hidden_dim*4, hidden_dim*2) self.fc3 = nn.Linear(hidden_dim*2, hidden_dim) self.fc4 = nn.Linear(hidden_dim, output_size) self.dropout = nn.Dropout(0.3) def forward(self, x): # flatten image x = x.view(-1, 28*28) x = F.leaky_relu(self.fc1(x), 0.2) x = self.dropout(x) x = F.leaky_relu(self.fc2(x), 0.2) x = self.dropout(x) x = F.leaky_relu(self.fc3(x), 0.2) x = self.dropout(x) out = F.log_softmax(self.fc4(x)) return out  The D network has 4 linear layers with leaky relu and dropout layers in between.\nHere the input size will be 28*28*1 (size of MNIST image)\nhidden dim can be anything of your choice.\noutput_size = 2 (real or fake)\nI am also adding a log softmax in the end for computation purpose.\nLets make a Discriminator object\nD_network = D(28*28*1, 50, 2) print(D_network)  output :\nD( (fc1): Linear(in_features=784, out_features=200, bias=True) (fc2): Linear(in_features=200, out_features=100, bias=True) (fc3): Linear(in_features=100, out_features=50, bias=True) (fc4): Linear(in_features=50, out_features=2, bias=True) (dropout): Dropout(p=0.3) )  Generator The Generator takes a random vector(z)(also called latent vector) and generates a sample image with a distribution close to the training data distribution. We want to upsample z to an image of size 1*28*28. Tanh was used as activation in the output layer(as used in the original paper) , but feel free to try other activations and check which gives good result.\nclass G(nn.Module): def __init__(self, input_size, hidden_dim, output_size): super(G, self).__init__() self.fc1 = nn.Linear(input_size, hidden_dim) self.fc2 = nn.Linear(hidden_dim, hidden_dim*2) self.fc3 = nn.Linear(hidden_dim*2, hidden_dim*4) self.fc4 = nn.Linear(hidden_dim*4, output_size) self.dropout = nn.Dropout(0.3) def forward(self, x): x = F.leaky_relu(self.fc1(x), 0.2) x = self.dropout(x) x = F.leaky_relu(self.fc2(x), 0.2) x = self.dropout(x) x = F.leaky_relu(self.fc3(x), 0.2) x = self.dropout(x) out = F.tanh(self.fc4(x)) return out  The G network architecture is same as D\u0026rsquo;s architecture except now we upsample the z to 28*28*1 size image.\nG_network = G(100, 50, 1*28*28) print(G_network)  G( (fc1): Linear(in_features=100, out_features=50, bias=True) (fc2): Linear(in_features=50, out_features=100, bias=True) (fc3): Linear(in_features=100, out_features=200, bias=True) (fc4): Linear(in_features=200, out_features=784, bias=True) (dropout): Dropout(p=0.3) )  Loss The discriminator wants the probability of fake images close to 0 and the generator wants the probability of the fake images generated by it to be close to 1.\nSo we define 2 losses\n Real Loss (loss btw p and 1) Fake loss (loss btw p and 0)  p is the probability of image to be real.\n For Generator : minimize real_loss(p) or p to be closer to 1. ie: fool generator by making realistic images.\n For Discriminator : minimize real_loss + fake loss. ie: p of real image close to 1 and p of fake image close to 0.\n  def real_loss(D_out, smooth=False): batch_size = D_out.size(0) # label smoothing if smooth: # smooth, real labels = 0.9 labels = torch.ones(batch_size)*0.9 else: labels = torch.ones(batch_size) # real labels = 1 criterion = nn.NLLLoss() loss = criterion(D_out.squeeze(), labels.long().cuda()) return loss def fake_loss(D_out): batch_size = D_out.size(0) labels = torch.zeros(batch_size) # fake labels = 0 criterion = nn.NLLLoss() loss = criterion(D_out.squeeze(), labels.long().cuda()) return loss  label smoothing is also done for better convergence.\nTraining We will use 2 optimizers\n One for Generator, which optimizes the real_loss of fake images. ie: it tries to make the classification prediction of fake images equal to 1. Next is discriminator, which tries to optimize real+fake loss. ie: it tries to make the prediciton of fake images to 0 and real images to 1.  Adjust the no of epochs, latent vector size, optimizer parameters, dimensions etc.\nnum_epochs = 100 print_every = 400 # train the network D.train() G.train() for epoch in range(num_epochs): for batch_i, (images, _) in enumerate(train_loader): batch_size = images.size(0) ## Important rescaling step ## real_images = images*2 - 1 # rescale input images from [0,1) to [-1, 1) d_optimizer.zero_grad() D_real = D(real_images) d_real_loss = real_loss(D_real, smooth=True) z = np.random.uniform(-1, 1, size=(batch_size, z_size)) z = torch.from_numpy(z).float() fake_images = G(z) D_fake = D(fake_images) d_fake_loss = fake_loss(D_fake) d_loss = d_real_loss + d_fake_loss d_loss.backward() d_optimizer.step() g_optimizer.zero_grad() z = np.random.uniform(-1, 1, size=(batch_size, z_size)) z = torch.from_numpy(z).float() fake_images = G(z) D_fake = D(fake_images) g_loss = real_loss(D_fake) g_optimizer.step() if batch_i % print_every == 0: print('Epoch {:5d}/{:5d}\\td_loss: {:6.4f}\\tg_loss: {:6.4f}'.format( epoch+1, num_epochs, d_loss.item(), g_loss.item()))  Epoch 1/ 100 d_loss: 1.3925 g_loss: 0.6747 Epoch 2/ 100 d_loss: 1.2275 g_loss: 0.6837 Epoch 3/ 100 d_loss: 1.0829 g_loss: 0.6959 Epoch 4/ 100 d_loss: 1.0295 g_loss: 0.7128 Epoch 5/ 100 d_loss: 1.0443 g_loss: 0.7358 Epoch 6/ 100 d_loss: 1.0362 g_loss: 0.7625 Epoch 7/ 100 d_loss: 0.9942 g_loss: 0.8000 Epoch 8/ 100 d_loss: 0.9445 g_loss: 0.8455 Epoch 9/ 100 d_loss: 0.9005 g_loss: 0.9073 Epoch 10/ 100 d_loss: 0.8604 g_loss: 0.9908 ...  Generate new MNIST Samples def view_samples(epoch, samples): fig, axes = plt.subplots(figsize=(7,7), nrows=4, ncols=4, sharey=True, sharex=True) for ax, img in zip(axes.flatten(), samples[epoch]): img = img.detach() ax.xaxis.set_visible(False) ax.yaxis.set_visible(False) im = ax.imshow(img.reshape((28,28)), cmap='Greys_r') sample_size=16 rand_z = np.random.uniform(-1, 1, size=(sample_size, z_size)) rand_z = torch.from_numpy(rand_z).float() G.eval() rand_images = G(rand_z) view_samples(0, [rand_images])  Linear GAN Model does a decent job in generating MNIST images. In next post we will look into DCGAN(Deep Convolutional GAN), to use CNNs for generating new samples.\nCheck this Awesome Repo on comparing Linear GAN and DCGAN for MNIST. Also this notebook for pytorch implementation of vanilla GAN(Linear).\n","date":1558410180,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558410180,"objectID":"14121bcbbeb0a6d310e1ce83d1b3402e","permalink":"/post/gan-3/","publishdate":"2019-05-21T03:43:00Z","relpermalink":"/post/gan-3/","section":"post","summary":"MNIST Linear GAN","tags":["Deep Learning post","GAN post## Supervised learning"],"title":"GAN 3","type":"post"},{"authors":["Shangeth Rajaa"],"categories":["Deep Learning","Python","PyTorch"],"content":" As we saw in Intro and application of Generative Adversarial Network, GANs generate new data from a given dataset by learning the distribution of the dataset through adversarial process.\nWhat is an adversarial process/learning? A google search can tell you that adversarial machine learning is a technique used in Machine Learning which tries to fool the model by giving in false/malicious input.\nComponents of GANs:  Generator The Generator network takes random noise as input and convert it to a data sample(image/music) . The output of generator is a fake but realistic data sample. The choice of the random noise determines the distribution into which the data sample generated falls.\nBut the generator network have to be trained to produce samples for the given random noise. ie: the generator have to learn the distribution of the dataset, so it generates new data samples from the distribution.\nAs this is not a supervised learning, we cannot use labels to learn the parameters of generator. So we use adversarial learning technique to learn the distribution of the dataset.\nThe idea is to maximize the probability that the data sample generated by the generator is from the training dataset. But it is not easy as its un labelled , so we use the help of another network called Discriminator.\n Discriminator Discriminator is a normal Neural Network classifier. The discriminator finds if a data sample is from the training dataset or not.\nDuring the training process, the discriminator is given data from the training dataset 50% of the time and data samples generated by generator other 50% of the time. The discriminator classifies the generated data samples as fake and data from the training dataset as real data.\n  The Game Theory As the disciminator classifies the data sample from the generator as fake, the generator tries to fool the discriminator by generating more realistic data sample(learns the training data distribution well). The generator starts generating samples more close to the distribution of the training dataset.\nAs the generator tries to fool the discriminator, the discriminator learns to classify the more realistic(fake) data generated by the generator as fake. By this process both the networks learn the parameters which gives best results. This creates a competition between Generator(G) and Discriminator(D), this makes this an adversarial learning.\nCheck this\nIn game theory, an equlibrium is reached in a 2 player game when both the players recieve 0 payoff. When a player(P) wins, P gets a positive payoff of 1 and gets a negative payoff of -1 when loses. When a player loses, the player changes the stratergy to win the next round. As this continues the player becomes better but as the other player also gets better , an equilibrium is reached when both players uses random uniform stratergies. At equilibrium, neither of the players can improve further.\nMost of the machine learning models we used so far depends on optimization algorithms. We finds a set of parameters for which the cost function is minimum. But GANs have 2 players G \u0026amp; D. The G is trying to fool D and D is trying to classify G\u0026rsquo;s sample as fake data. As we can see D is trying to minimize the probability of G\u0026rsquo;s output as true data, whereas G is trying to increase the probability.\nCost of D = minimize(P(generated sample data is real)) Cost of G = maximize(P(generated sample data is real))  Theoritically equlibrium occurs when both probabilities are equal.\nP(generated sample data is real) = 0.5  This occurs for a set of parameters for which the G got the maximum probability and D got minimum probability. ie: a saddle point.\nsaddle point - both local maxima and local minima\nGenerator gets a local maxima when the distribution learned by generator is equal to the distribution of the training dataset.\nWe will use 2 seperate optimization algorithms for D and G, so it is not possible for us to find the equilibrium. But if we can use a single optimization algorithm which reduces both D \u0026amp; G costs together, then we may encounter perfect equilibirum.\nIn the next post, we will look into the practical implementation of GANs by coding and training it in PyTorch.\n","date":1558406580,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558406580,"objectID":"d9d7cbd874401a4d0fb6f47eb32582a2","permalink":"/post/gan-2/","publishdate":"2019-05-21T02:43:00Z","relpermalink":"/post/gan-2/","section":"post","summary":"Theory of Game between Generator and Discriminator","tags":["Deep Learning post","GAN post"],"title":"GAN 2","type":"post"},{"authors":["Shangeth Rajaa"],"categories":["Deep Learning"],"content":" GANs are ML models that can imagine new things. GANs can generate new data with a given dataset by learning its distribution. GANs have been mostly used with image data but can also be used on any kind of data. GANs draw a sample from the learned probability distribution of the dataset which is a completely new sample.\nGANs are unsupervised machine learning models , which learns the distribution of the data through adverserial process and generate new sample from the learned distribution.\nSome Recent Research in GAN  Stack GAN Stack GAN can take a description of an image and can generate new images matching that description. GAN picks a sample from a distribution of images which matches the description. slide\n iGAN iGANs can search for realistic possible image as the user draws the rough sketch.\nGithub\n Pix2Pix Images in one domain can be changed to image in another domain with GANS. Rough sketches can be made into a realistic image which are generated by GANs. Blue Prints of a building can be changed to an image of finished building with GANs. Github\n Many other applications like photos to cartoons, daylight image to night scene image, Cycle GAN.\n  Check out all of these Generative models.\nIn the next few posts, we will look deep into how GANs work and code GANs with PyTorch for different applications.\n","date":1558317600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558317600,"objectID":"029dbda1937caf638b86fb2868753ab1","permalink":"/post/gan-1/","publishdate":"2019-05-20T02:00:00Z","relpermalink":"/post/gan-1/","section":"post","summary":"Intro and applications of Generative Adversarial Network","tags":["Deep Learning post","GAN post## Supervised learning"],"title":"GAN 1","type":"post"},{"authors":["Shangeth Rajaa"],"categories":["Deep Learning","Unsupervised Learning"],"content":" Machine Learning is broadly divided into 3 types:  Supervised learning Unsupervised learning Reinforcement learning  \nSupervised Learning The task in supervised learning is to learn a function to map a data X to a label y. All the classification, regression, object detection/recognition/segmentation generally comes under supervised learning.\nIn supervised learning we have a dataset which contains data X and label y and we need to learn how to find y given X.\nUnsupervised Learning In unsupervised learning, we only have X and not the respective y. The goal is to learn the underlying structure/features of the dataset without any label.\nSome examples of Unsupervised Learning are\n Clustering Clustering is dividing the data into groups through some distance metric, like kmeans clustering.  Feature Learning As the name suggest, learning the features of each of the given data, without its label. This is generally done with a help of a model called Autoencoders.\nAutoencoders take the data X as the label y , it try to recreate the data X given data X and learns some underlying features in that process. We generally take the one of the middle layers of the autoencoder as the encoded feature.  Dimensionality Reduction As we know data can be multi dimensional which can extent even to millions. Computation and visualization of such multi dimensioanl data is difficult and thus we want to reduce the dimension of the data (to pick the dimensions which can represent the data more).\nDimensionality reduction is done by choosing the axis in the data space along which variance of the data is high.  and many other examples like data compression(using auto encoders), Generative models, density estimation, etc.\n  Why Unsupervised Learning?  Unsupervised learning doesn\u0026rsquo;t need labels. Making the training data for supervised learning is not easy. Its expensive, time consuming, labour consuming. The world has a lot of unlabelled data, which can be used directly or with a little pre processing for unsupervised learning.  Unsupervised Learning is still an ameature area of research, which has a lot of potential. Unsupervised learning is less expensive and can accelerate the AI field so much.\n","date":1558310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558310400,"objectID":"27d1b98c303c07483ea9cb766eb656b5","permalink":"/post/unsupervised-learning/","publishdate":"2019-05-20T00:00:00Z","relpermalink":"/post/unsupervised-learning/","section":"post","summary":"Intro to Unsupervised Learning","tags":["Deep Learning post","Unsupervised Learning post"],"title":"Unsupervised Learning 101","type":"post"},{"authors":[],"categories":null,"content":"","date":1555160400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555160400,"objectID":"d13b1f263203cf0884ea5e3c60769dad","permalink":"/talk/icacds/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/icacds/","section":"talk","summary":"Presentation of my paper \"Convolutional Feature Extraction and Neural Arithmetic Logic Units for Stock Prediction\" at ICACDS 2019 Conference.","tags":[],"title":"Convolutional Feature Extraction and Neural Arithmetic Logic Units for Stock Prediction","type":"talk"},{"authors":["Shangeth Rajaa"],"categories":null,"content":" Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":[],"categories":null,"content":"","date":1547236800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547236800,"objectID":"381eff0b30d0969cc6d6ae0655de9911","permalink":"/talk/multi-tasking-learning/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/multi-tasking-learning/","section":"talk","summary":"A Talk on Multitasking learning as best project chosen by FacebookAI and Udacity.","tags":[],"title":"Multi Tasking Learning","type":"talk"},{"authors":["Shangeth Rajaa","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Shangeth Rajaa","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"","tags":null,"title":"","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"33c96636b53dc0f2a4842dacad9785a8","permalink":"/project/character-generating-rnn/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/character-generating-rnn/","section":"project","summary":"Character level language model of RNN(LSTM) in PyTorch.","tags":["Deep Learning","Python","NLP","PyTorch"],"title":"Character Generating RNN","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"bf3e111ff5fa7319b68614400b61b81d","permalink":"/project/computer-vision-security-system/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/computer-vision-security-system/","section":"project","summary":"Computer vision security system server build with Python, OpenCV, Flask web server.","tags":["Computer Vision","Python","JavaScript"],"title":"Computer Vision Security System","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"282a173f5eca67ca5c3b6c142509f212","permalink":"/project/emojification/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/emojification/","section":"project","summary":"Emojify a sentence with NLP, flask server to emojify a sentence.","tags":["Deep Learning","NLP","Python","Keras","JavaScript"],"title":"Emojification","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9e55cd99254ae71ee3e62fd187a803e2","permalink":"/project/hand-gesture-recognition/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/hand-gesture-recognition/","section":"project","summary":"Recognizing the hand gesture using CNN feature extraction.","tags":["Deep Learning","Computer Vision","Python","Tensorflow"],"title":"Hand Gesture Recognition","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"34b1e8cd4adc5242c33b8c3a394f1aa7","permalink":"/project/lane-detection/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/lane-detection/","section":"project","summary":"Lane Detection for self driving cars with Deep Learning(CNN) with the camera image data.","tags":["Deep Learning","Python","Computer Vision","Self Driving Cars","Keras"],"title":"Lane Detection with Deep Learning","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a5a90b199d4d8fa71f69281c9c521b93","permalink":"/project/multitasking-learning/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/multitasking-learning/","section":"project","summary":"Multitasking learning to use the CNN extracted features for multiple tasks like predicting age, sex, face direction, etc.","tags":["Deep Learning","Python","Computer Vision","Keras"],"title":"Multi Tasking Learning for face characterization","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ec641199efbb6bc51972564333aa628f","permalink":"/project/nytimes-topic-modelling/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/nytimes-topic-modelling/","section":"project","summary":"Topic Modelling for New York Times news articles for given dates using NYTimes API.","tags":["Topic Modelling","Python","NLP"],"title":"NYTimes Topic Modelling","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9b5611b35d0fe55dcb89e7cf0cd27239","permalink":"/project/neural-style-transfer/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/neural-style-transfer/","section":"project","summary":"Neural Style transfer of images in PyTorch.","tags":["Deep Learning","Python","Computer Vision","PyTorch"],"title":"Neural Style Transfer","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"05559a29ede4e1058072fa375b325d5e","permalink":"/project/pyrevshell/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/pyrevshell/","section":"project","summary":"A server client Reverse shell using python, can use any device's shell using this from another device in the network.","tags":["Python"],"title":"PyRevShell","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"befd31eb9f5cdc14aed99a7aac7c42ce","permalink":"/project/self-driving-cars-steering-angle-prediction/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/self-driving-cars-steering-angle-prediction/","section":"project","summary":"Prediction of which direction the car should change the steering direction in autonomous mode with the camera image as the input using transfer learning and fine tuning.","tags":["Deep Learning","Computer Vision","Self Driving Cars","Python","Tensorflow"],"title":"Self Driving Cars Steering Angle Prediction","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"90fc0166029130a6e9e179b6951e6cca","permalink":"/project/self-driving-cars-vehicle-detection/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/self-driving-cars-vehicle-detection/","section":"project","summary":"Detection of other vehicles for self driving cars with YOLO in tensorflow.","tags":["Deep Learning","Computer Vision","Self Driving Cars","Python","Tensorflow"],"title":"Self Driving Cars Vehicle Detection","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8491d5ad45e23efbef2c021b6d1d1f3e","permalink":"/project/seq2seq-machine-translation/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/seq2seq-machine-translation/","section":"project","summary":"Machine Translation english to french using Seq2Seq Attention model in PyTorch.","tags":["Deep Learning","Python","NLP","PyTorch"],"title":"Seq2Seq Machine Translation","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f116c6b6180f2fdf083da45996812e52","permalink":"/project/signature-verification/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/signature-verification/","section":"project","summary":"Signature verification with siamese network.","tags":["Deep Learning","Computer Vision"],"title":"Signature Verification with Deep Learning","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d67e120ff9736002127131016086076c","permalink":"/project/sockchat/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/sockchat/","section":"project","summary":"Sock Chat is a server-client chat application with database which can be used to any web server or software applications,","tags":["Python"],"title":"SockChat","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"28c0d4e4fc2f501dcb486c837c012cc7","permalink":"/project/tictactoe/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/tictactoe/","section":"project","summary":"2 player Tic Tac Toe game programmed in JavaScript.","tags":["JavaScript"],"title":"Tic Tac Toe","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cafd875167c47b3bd805f99a1d48fd56","permalink":"/project/nltk-sentiment-analysis/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/nltk-sentiment-analysis/","section":"project","summary":"Sentiment analysis of tweets of any topic fetched with twitter API and sentiment analysis of the tweets with NLTK.","tags":["NLP","Python","JavaScript"],"title":"Twitter Sentiment analysis","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"34c0ac182533d3a863fb69d13e227a5a","permalink":"/project/vehicle-speed-estimation/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/vehicle-speed-estimation/","section":"project","summary":"Estimation of a vehicle's speed with its camera frames using deep leanring in PyTorch.","tags":["Deep Learning","Python","Computer Vision","Self Driving Cars","PyTorch"],"title":"Vehicle Speed Estimation","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"bb5ee3b1d3ce8470980e92fe2fd3ca24","permalink":"/project/web-builder/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/web-builder/","section":"project","summary":"Live HTML, CSS, JavaScript code output.","tags":["JavaScript"],"title":"Web Builder","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5b420fd0a369ab016ae61c3b944068f2","permalink":"/project/weekly-scheduler/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/weekly-scheduler/","section":"project","summary":"This a web weekly scheduler build with JavaScript.","tags":["JavaScript"],"title":"Weekly Scheduler","type":"project"}]