<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.3.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Shangeth Rajaa">

  
  
  
    
  
  <meta name="description" content="Gradient Descent We have seen what are the steps followed in Gradient Descent to minimize the loss function. Now let&rsquo;s get into more detail.
The objective of gradient descent is to find $W, b$ for which $\mathcal{L}(W, b) $ is minimum for given pairs of data $(X, y)$.
Example Let&rsquo;s forget about Machine learning for sometime and use gradient descent algorithm for optimization of simple functions.
Given a function $y = f(x) = 0.">

  
  <link rel="alternate" hreflang="en-us" href="/courses/deeplearning/2.3/">

  


  

  

  

  

  

  

  
  
  
  <meta name="theme-color" content="hsl(339, 90%, 68%)">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light" disabled>
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark">
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.04bf00581ae5351cdd9e3f0836914cc1.css">

  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-134441268-1', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/courses/deeplearning/2.3/">

  
  
  
  
    
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@shangethr">
  <meta property="twitter:creator" content="@shangethr">
  
  <meta property="og:site_name" content="Shangeth">
  <meta property="og:url" content="/courses/deeplearning/2.3/">
  <meta property="og:title" content="Optimizers | Shangeth">
  <meta property="og:description" content="Gradient Descent We have seen what are the steps followed in Gradient Descent to minimize the loss function. Now let&rsquo;s get into more detail.
The objective of gradient descent is to find $W, b$ for which $\mathcal{L}(W, b) $ is minimum for given pairs of data $(X, y)$.
Example Let&rsquo;s forget about Machine learning for sometime and use gradient descent algorithm for optimization of simple functions.
Given a function $y = f(x) = 0."><meta property="og:image" content="/img/instructor2.jpeg">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2019-09-03T00:00:00&#43;01:00">
  
  <meta property="article:modified_time" content="2019-09-03T00:00:00&#43;01:00">
  

  

  

  <title>Optimizers | Shangeth</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" class="dark">
  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Shangeth</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#featured">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link  active" href="/courses/">
            
            <span>Deep Learning Course</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>



<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      




<form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-3" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <span><i class="fas fa-bars"></i></span>
  </button>

  
  <input name="q" type="search" class="form-control" id="search-query" placeholder="Search..." autocomplete="off">
  
</form>

<nav class="collapse docs-links" id="docs-nav">
  
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/courses/deeplearning/">Course Overview</a>

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/courses/deeplearning/0.1/">0.Data and Learning problem</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/courses/deeplearning/0.1/">0.1.Data and Learning Problem</a>
      </li>
      
    </ul>
    

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/courses/deeplearning/1.1/">1.Intro to Deep Learning</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/courses/deeplearning/1.1/">1.1.Linear Regression</a>
      </li>
      
      <li >
        <a href="/courses/deeplearning/1.2/">1.2.Assignment - Polynomial Regression</a>
      </li>
      
      <li >
        <a href="/courses/deeplearning/1.3/">1.3.Logistic Regression</a>
      </li>
      
      <li >
        <a href="/courses/deeplearning/1.4/">1.4.Assignment - Multiclass Classification</a>
      </li>
      
      <li >
        <a href="/courses/deeplearning/1.5/">1.5.Multi Layer Perceptron - Motivation</a>
      </li>
      
    </ul>
    

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/courses/deeplearning/2.1/">2.Deep Neural Networks</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/courses/deeplearning/2.1/">2.1.Neural Network Architectures</a>
      </li>
      
      <li >
        <a href="/courses/deeplearning/2.2/">2.2.Batch Training</a>
      </li>
      
      <li class="active">
        <a href="/courses/deeplearning/2.3/">2.3.Optimizers</a>
      </li>
      
      <li >
        <a href="/courses/deeplearning/2.4/">2.4.Learning Rate</a>
      </li>
      
      <li >
        <a href="/courses/deeplearning/2.5/">2.5.Bias &amp; Variance</a>
      </li>
      
      <li >
        <a href="/courses/deeplearning/2.6/">2.6.Overfitting &amp; Regularization</a>
      </li>
      
      <li >
        <a href="/courses/deeplearning/2.7/">2.7.ANN - Medical Diagnosis</a>
      </li>
      
      <li >
        <a href="/courses/deeplearning/2.8/">2.8.ANN - Computer Vision</a>
      </li>
      
      <li >
        <a href="/courses/deeplearning/2.9/">2.9.ANN - Natural Language Processing</a>
      </li>
      
    </ul>
    

  </div>
  
  
</nav>

    </div>

    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      
      <p class="docs-toc-title">On this page</p>
      

      <nav id="TableOfContents">
  <ul>
    <li><a href="#example">Example</a>
      <ul>
        <li><a href="#step---1">Step - 1</a></li>
        <li><a href="#step---2">Step - 2</a></li>
        <li><a href="#step---3-learning-rate">Step - 3 Learning rate</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#momentum-in-numpy">Momentum in Numpy</a></li>
  </ul>

  <ul>
    <li><a href="#sgd-optimizer">SGD optimizer</a>
      <ul>
        <li><a href="#stochastic-gradient-descent-without-momentum">Stochastic gradient descent without momentum</a></li>
        <li><a href="#stochastic-gradient-descent-with-momentum">Stochastic gradient descent with momentum</a></li>
      </ul>
    </li>
    <li><a href="#adam-optimizer">Adam optimizer</a></li>
  </ul>
</nav>

      <ul class="nav toc-top">
        <li><a href="#">Back to top</a></li>
      </ul>

      
    </div>
    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article" itemscope itemtype="http://schema.org/Article">

        <div class="docs-article-container">
          <h1 itemprop="name">Optimizers</h1>

          <div class="article-style" itemprop="articleBody">
            <p><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<h1 id="gradient-descent">Gradient Descent</h1>
<p>We have seen what are the steps followed in Gradient Descent to minimize the loss function. Now let&rsquo;s get into more detail.</p>
<p>The objective of gradient descent is to find $W, b$ for which $\mathcal{L}(W, b) $ is minimum for given pairs of data $(X, y)$.</p>
<h2 id="example">Example</h2>
<p>Let&rsquo;s forget about Machine learning for sometime and use gradient descent algorithm for optimization of simple functions.</p>
<p>Given a function $y = f(x) = 0.08x^2+sin(x)$, the objective is to find $x$ at which $y = f(x)$ is minimum.</p>
<p>Let&rsquo;s use Numpy to solve this.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">f</span>(x):
    <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">0.08</span><span style="color:#f92672">*</span> x<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>sin(x)

x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(<span style="color:#f92672">-</span><span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">0.01</span>)
y <span style="color:#f92672">=</span> f(x)

plt<span style="color:#f92672">.</span>plot(x, y, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;$y = f(x)$&#39;</span>)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;$x$&#39;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;$y$&#39;</span>)
plt<span style="color:#f92672">.</span>legend()
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="../2_3/output_3_0.png" alt="png"></p>
<p>We are going to use gradient descent to find $x$ for which this function is minimum.</p>
<h3 id="step---1">Step - 1</h3>
<p>Choose a random point</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">random_idx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>choice(<span style="color:#ae81ff">2000</span>)
random_x <span style="color:#f92672">=</span> x[random_idx]

plt<span style="color:#f92672">.</span>plot(x, y, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;$y = f(x)$&#39;</span>)
plt<span style="color:#f92672">.</span>scatter(random_x, f(random_x))
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;$x$&#39;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;$y$&#39;</span>)
plt<span style="color:#f92672">.</span>legend()
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="../2_3/output_6_0.png" alt="png"></p>
<h3 id="step---2">Step - 2</h3>
<p>calculate $\dfrac{\partial \mathcal{y}}{\partial x}$.</p>
<p>Why? Let&rsquo;s visualize it</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">60</span>)

random_idx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>choice(<span style="color:#ae81ff">2000</span>)
random_x <span style="color:#f92672">=</span> x[random_idx]

a <span style="color:#f92672">=</span> random_x
h <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.01</span>
x_tan <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(a<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, a<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0.01</span>)
fprime <span style="color:#f92672">=</span> (f(a<span style="color:#f92672">+</span>h)<span style="color:#f92672">-</span>f(a))<span style="color:#f92672">/</span>h
tan <span style="color:#f92672">=</span> f(a)<span style="color:#f92672">+</span>fprime<span style="color:#f92672">*</span>(x_tan<span style="color:#f92672">-</span>a)  

plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12</span>,<span style="color:#ae81ff">8</span>))
plt<span style="color:#f92672">.</span>plot(x, y, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;$y = f(x)$&#39;</span>)
plt<span style="color:#f92672">.</span>plot(x_tan, tan, <span style="color:#e6db74">&#39;--&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;gradient $\dfrac{\partial \mathcal{y}}{\partial x}$&#39;</span>, linewidth<span style="color:#f92672">=</span><span style="color:#ae81ff">4.0</span>)
plt<span style="color:#f92672">.</span>text(a<span style="color:#f92672">+</span><span style="color:#ae81ff">0.2</span>,f(a<span style="color:#f92672">+</span><span style="color:#ae81ff">0.2</span>),<span style="color:#e6db74">&#39;$\dfrac{\partial \mathcal{y}}{\partial x}$=&#39;</span><span style="color:#f92672">+</span><span style="color:#e6db74">&#39;{:.3f}&#39;</span><span style="color:#f92672">.</span>format(fprime), fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)
plt<span style="color:#f92672">.</span>scatter(random_x, f(random_x), s<span style="color:#f92672">=</span><span style="color:#ae81ff">200</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;black&#39;</span>)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;$x$&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;$y$&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)
plt<span style="color:#f92672">.</span>legend(fontsize <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;xx-large&#39;</span>)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="../2_3/output_8_0.png" alt="png"></p>
<p>The gradient of $y = f(x) = 0.08x^2+sin(x)$ is $\dfrac{\partial \mathcal{y}}{\partial x} = 0.16x+cos(x)$</p>
<p>The gradient or slope $\dfrac{\partial \mathcal{y}}{\partial x}$ of the curve at the randomly selected point is negative. Which means the function will decrease as x increases and the function will increase as x decreases.</p>
<p>Our objective is to minimize the function, so we calculate $\dfrac{\partial \mathcal{y}}{\partial x}$, to decide in which direction to move, so we reach the minimum.</p>
<ul>
<li>if $\dfrac{\partial \mathcal{y}}{\partial x} &gt; 0$, we move towards left of decrease x</li>
<li>if $\dfrac{\partial \mathcal{y}}{\partial x} &lt; 0$, we move towards right or increase x</li>
<li>if $\dfrac{\partial \mathcal{y}}{\partial x} = 0$, which means we are already at a point of minimum</li>
</ul>
<p>But how much to increase x?</p>
<h3 id="step---3-learning-rate">Step - 3 Learning rate</h3>
<p>We now know, given a point should we increase or decrease x to reach minimum.</p>
<p>How much to increase or decrease x?</p>
<p>We change x with a factor called learning rate $\alpha$.
So we update x with $x := x - \alpha \frac{\partial \mathcal{y}}{\partial x}$</p>
<ul>
<li>when $\alpha$ is small, x is increased in small steps, so more iterations are required to reach minimum, but this will lead to more accurate steps.</li>
<li>when $\alpha$ is larger, x will increase in larger steps, so x will reach minimum y in few steps, but there is a risk of x skipping the minimum point, as x is increased in larger value.</li>
</ul>
<p>When do we stop?
We can iterate of any number of iterations, but when x reaches minimum y , then $\dfrac{\partial \mathcal{y}}{\partial x} = 0$</p>
<p>$\therefore x := x - \alpha . 0$, so x will remain the same, even if you iterate more.</p>
<p>Let&rsquo;s code this.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">gradient</span>(x):
    <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">0.16</span><span style="color:#f92672">*</span>x<span style="color:#f92672">+</span>np<span style="color:#f92672">.</span>cos(x)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">24</span>) <span style="color:#75715e"># change the seed to start from different points</span>

x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(<span style="color:#f92672">-</span><span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">0.01</span>)
y <span style="color:#f92672">=</span> f(x)

random_idx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>choice(<span style="color:#ae81ff">2000</span>)
x_iter <span style="color:#f92672">=</span> x[random_idx]

epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
lr <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.2</span>

<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(epochs):
    dy_dx <span style="color:#f92672">=</span> gradient(x_iter)    
    x_iter <span style="color:#f92672">=</span> x_iter <span style="color:#f92672">-</span> lr <span style="color:#f92672">*</span> dy_dx


    <span style="color:#66d9ef">if</span> i<span style="color:#f92672">%</span><span style="color:#ae81ff">20</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
        a <span style="color:#f92672">=</span> x_iter
        h <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.01</span>
        x_tan <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(a<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, a<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0.01</span>)
        fprime <span style="color:#f92672">=</span> (f(a<span style="color:#f92672">+</span>h)<span style="color:#f92672">-</span>f(a))<span style="color:#f92672">/</span>h
        tan <span style="color:#f92672">=</span> f(a)<span style="color:#f92672">+</span>fprime<span style="color:#f92672">*</span>(x_tan<span style="color:#f92672">-</span>a)  

        plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12</span>,<span style="color:#ae81ff">8</span>))
        plt<span style="color:#f92672">.</span>plot(x, y, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;$y = f(x)$&#39;</span>)
        plt<span style="color:#f92672">.</span>plot(x_tan, tan, <span style="color:#e6db74">&#39;--&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;gradient $\dfrac{\partial \mathcal{y}}{\partial x}$&#39;</span>, linewidth<span style="color:#f92672">=</span><span style="color:#ae81ff">4.0</span>)
        plt<span style="color:#f92672">.</span>text(a<span style="color:#f92672">+</span><span style="color:#ae81ff">0.2</span>,f(a<span style="color:#f92672">+</span><span style="color:#ae81ff">0.2</span>),<span style="color:#e6db74">&#39;$\dfrac{\partial \mathcal{y}}{\partial x}$=&#39;</span><span style="color:#f92672">+</span><span style="color:#e6db74">&#39;{:.3f}&#39;</span><span style="color:#f92672">.</span>format(fprime), fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)
        plt<span style="color:#f92672">.</span>scatter(a, f(a), s<span style="color:#f92672">=</span><span style="color:#ae81ff">200</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;black&#39;</span>)
        plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;$x$&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)
        plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;$y$&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)
        plt<span style="color:#f92672">.</span>legend(fontsize <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;xx-large&#39;</span>)
        plt<span style="color:#f92672">.</span>show()



</code></pre></div><p><img src="../2_3/output_11_0.png" alt="png"></p>
<p><img src="../2_3/output_11_1.png" alt="png"></p>
<p><img src="../2_3/output_11_2.png" alt="png"></p>
<p><img src="../2_3/output_11_3.png" alt="png"></p>
<p><img src="../2_3/output_11_4.png" alt="png"></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">24</span>) <span style="color:#75715e"># change the seed to start from different points</span>

x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(<span style="color:#f92672">-</span><span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">0.01</span>)
y <span style="color:#f92672">=</span> f(x)

random_idx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>choice(<span style="color:#ae81ff">2000</span>)
x_iter <span style="color:#f92672">=</span> x[random_idx]

epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
lr <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.2</span>

x_list <span style="color:#f92672">=</span> []
y_list <span style="color:#f92672">=</span> []

<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(epochs):
    dy_dx <span style="color:#f92672">=</span> gradient(x_iter)
    
    x_iter <span style="color:#f92672">=</span> x_iter <span style="color:#f92672">-</span> lr <span style="color:#f92672">*</span> dy_dx
    x_list<span style="color:#f92672">.</span>append(x_iter)
    y_list<span style="color:#f92672">.</span>append(f(x_iter))

plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12</span>,<span style="color:#ae81ff">8</span>))
plt<span style="color:#f92672">.</span>plot(x, y, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;$y = f(x)$&#39;</span>)
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(x_list)):
    plt<span style="color:#f92672">.</span>scatter(x_list[i], y_list[i], s<span style="color:#f92672">=</span><span style="color:#ae81ff">200</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;black&#39;</span>)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;$x$&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;$y$&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)
plt<span style="color:#f92672">.</span>legend(fontsize <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;xx-large&#39;</span>)
plt<span style="color:#f92672">.</span>show()



</code></pre></div><p><img src="../2_3/output_12_0.png" alt="png"></p>
<p>This is the path followed to reach the minimum.</p>
<p><strong>Run the code</strong> with</p>
<ul>
<li>large lr</li>
<li>small lr</li>
<li>more epochs</li>
<li>less epochs</li>
</ul>
<h1 id="gd-with-momentum">GD with Momentum</h1>
<p>The updation step is changed with</p>
<p>$v = \beta v + (1-\beta) \dfrac{\partial \mathcal{y}}{\partial x}$</p>
<p>$x = x - \alpha v$</p>
<p>This algorithms smoothens the updation process, by averaging the movement in other the direction and forces x to move in the required direction which fastens the process.</p>
<h2 id="momentum-in-numpy">Momentum in Numpy</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">23</span>) <span style="color:#75715e"># change the seed to start from different points</span>

x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(<span style="color:#f92672">-</span><span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">0.01</span>)
y <span style="color:#f92672">=</span> f(x)

random_idx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>choice(<span style="color:#ae81ff">2000</span>)
x_iter <span style="color:#f92672">=</span> x[random_idx]

epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
lr <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.2</span>
v <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
b <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.9</span>

<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(epochs):
    dy_dx <span style="color:#f92672">=</span> gradient(x_iter)
    v <span style="color:#f92672">=</span> b <span style="color:#f92672">*</span> v <span style="color:#f92672">+</span> (<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>b) <span style="color:#f92672">*</span>  dy_dx   
    x_iter <span style="color:#f92672">=</span> x_iter <span style="color:#f92672">-</span> lr <span style="color:#f92672">*</span> v


    <span style="color:#66d9ef">if</span> i<span style="color:#f92672">%</span><span style="color:#ae81ff">20</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
        a <span style="color:#f92672">=</span> x_iter
        h <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.01</span>
        x_tan <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(a<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, a<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0.01</span>)
        fprime <span style="color:#f92672">=</span> (f(a<span style="color:#f92672">+</span>h)<span style="color:#f92672">-</span>f(a))<span style="color:#f92672">/</span>h
        tan <span style="color:#f92672">=</span> f(a)<span style="color:#f92672">+</span>fprime<span style="color:#f92672">*</span>(x_tan<span style="color:#f92672">-</span>a)  

        plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12</span>,<span style="color:#ae81ff">8</span>))
        plt<span style="color:#f92672">.</span>plot(x, y, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;$y = f(x)$&#39;</span>)
        plt<span style="color:#f92672">.</span>plot(x_tan, tan, <span style="color:#e6db74">&#39;--&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;gradient $\dfrac{\partial \mathcal{y}}{\partial x}$&#39;</span>, linewidth<span style="color:#f92672">=</span><span style="color:#ae81ff">4.0</span>)
        plt<span style="color:#f92672">.</span>text(a<span style="color:#f92672">+</span><span style="color:#ae81ff">0.2</span>,f(a<span style="color:#f92672">+</span><span style="color:#ae81ff">0.2</span>),<span style="color:#e6db74">&#39;$\dfrac{\partial \mathcal{y}}{\partial x}$=&#39;</span><span style="color:#f92672">+</span><span style="color:#e6db74">&#39;{:.3f}&#39;</span><span style="color:#f92672">.</span>format(fprime), fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)
        plt<span style="color:#f92672">.</span>scatter(a, f(a), s<span style="color:#f92672">=</span><span style="color:#ae81ff">200</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;black&#39;</span>)
        plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;$x$&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)
        plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;$y$&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)
        plt<span style="color:#f92672">.</span>legend(fontsize <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;xx-large&#39;</span>)
        plt<span style="color:#f92672">.</span>show()



</code></pre></div><p><img src="../2_3/output_15_0.png" alt="png"></p>
<p><img src="../2_3/output_15_1.png" alt="png"></p>
<p><img src="../2_3/output_15_2.png" alt="png"></p>
<p><img src="../2_3/output_15_3.png" alt="png"></p>
<p><img src="../2_3/output_15_4.png" alt="png"></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">24</span>) <span style="color:#75715e"># change the seed to start from different points</span>

x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(<span style="color:#f92672">-</span><span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">0.01</span>)
y <span style="color:#f92672">=</span> f(x)

random_idx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>choice(<span style="color:#ae81ff">2000</span>)
x_iter <span style="color:#f92672">=</span> x[random_idx]

epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">200</span>
lr <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.1</span>
v <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
b <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.9</span>

x_list <span style="color:#f92672">=</span> []
y_list <span style="color:#f92672">=</span> []

<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(epochs):
    dy_dx <span style="color:#f92672">=</span> gradient(x_iter)
    
    v <span style="color:#f92672">=</span> b <span style="color:#f92672">*</span> v <span style="color:#f92672">+</span> (<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>b) <span style="color:#f92672">*</span>  dy_dx   
    x_iter <span style="color:#f92672">=</span> x_iter <span style="color:#f92672">-</span> lr <span style="color:#f92672">*</span> v

    x_list<span style="color:#f92672">.</span>append(x_iter)
    y_list<span style="color:#f92672">.</span>append(f(x_iter))

plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12</span>,<span style="color:#ae81ff">8</span>))
plt<span style="color:#f92672">.</span>plot(x, y, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;$y = f(x)$&#39;</span>)
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(x_list)):
    plt<span style="color:#f92672">.</span>scatter(x_list[i], y_list[i], s<span style="color:#f92672">=</span><span style="color:#ae81ff">200</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;black&#39;</span>)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;$x$&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;$y$&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)
plt<span style="color:#f92672">.</span>legend(fontsize <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;xx-large&#39;</span>)
plt<span style="color:#f92672">.</span>show()



</code></pre></div><p><img src="../2_3/output_16_0.png" alt="png"></p>
<h1 id="optimization-algorithms-with-tensorflow">Optimization algorithms with Tensorflow</h1>
<p>Check the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers">Tensorflow docs</a>.</p>
<p>So far we have been using &lsquo;Adam&rsquo; algorithm for optimization with default parameter values. We will now train models with different optimizers and hyper parameters.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> make_gaussian_quantiles
<span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt

X, y <span style="color:#f92672">=</span> make_gaussian_quantiles(n_samples<span style="color:#f92672">=</span><span style="color:#ae81ff">2000</span>, n_features<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, n_classes<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, cov<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>)

plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">10</span>,<span style="color:#ae81ff">10</span>))
plt<span style="color:#f92672">.</span>scatter(X[:,<span style="color:#ae81ff">0</span>], X[:,<span style="color:#ae81ff">1</span>],c<span style="color:#f92672">=</span>y)
plt<span style="color:#f92672">.</span>grid(True)
plt<span style="color:#f92672">.</span>show()


X_train, X_test, y_train, y_test <span style="color:#f92672">=</span> train_test_split(X, y, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.3</span>, shuffle<span style="color:#f92672">=</span>True)
X_train, X_val, y_train, y_val <span style="color:#f92672">=</span> train_test_split(X_train, y_train, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, shuffle<span style="color:#f92672">=</span>True)

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Train = {}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Test = {}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Val = {}&#39;</span><span style="color:#f92672">.</span>format(len(X_train), len(X_test), len(X_val)))
</code></pre></div><p><img src="../2_3/output_18_0.png" alt="png"></p>
<pre><code>Train = 1120
Test = 600
Val = 280
</code></pre>
<h2 id="sgd-optimizer">SGD optimizer</h2>
<h3 id="stochastic-gradient-descent-without-momentum">Stochastic gradient descent without momentum</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf
<span style="color:#f92672">from</span> tensorflow <span style="color:#f92672">import</span> keras
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>backend<span style="color:#f92672">.</span>clear_session()

<span style="color:#75715e"># random number initialized to same, for reproducing the same results.</span>
np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">0</span>)
tf<span style="color:#f92672">.</span>set_random_seed(<span style="color:#ae81ff">0</span>)

model <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>Sequential([
                             keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Dense(units<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>, input_shape<span style="color:#f92672">=</span>[<span style="color:#ae81ff">2</span>]), 
                             keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Activation(<span style="color:#e6db74">&#39;tanh&#39;</span>),
                             keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Dense(units<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>),
                             keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Activation(<span style="color:#e6db74">&#39;tanh&#39;</span>),
                             keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Dense(units<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>), 
                             keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Activation(<span style="color:#e6db74">&#39;sigmoid&#39;</span>)
                             ])

<span style="color:#75715e"># we used the default optimizer parameters by using optimizer=&#39;adam&#39;</span>
<span style="color:#75715e"># model.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])</span>

<span style="color:#75715e"># we can also define optimizer with</span>
optimizer <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>optimizers<span style="color:#f92672">.</span>SGD(lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, nesterov<span style="color:#f92672">=</span>False)
model<span style="color:#f92672">.</span>compile(optimizer<span style="color:#f92672">=</span>optimizer, loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;binary_crossentropy&#39;</span>, metrics<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;accuracy&#39;</span>])
tf_history <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>fit(X_train, y_train, batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>, verbose<span style="color:#f92672">=</span>True, validation_data<span style="color:#f92672">=</span>(X_val, y_val))


<span style="color:#75715e"># contour plot</span>
xx, yy <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>mgrid[<span style="color:#f92672">-</span><span style="color:#ae81ff">1.5</span>:<span style="color:#ae81ff">1.5</span>:<span style="color:#f92672">.</span><span style="color:#ae81ff">01</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1.5</span>:<span style="color:#ae81ff">1.5</span>:<span style="color:#f92672">.</span><span style="color:#ae81ff">01</span>]
grid <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>c_[xx<span style="color:#f92672">.</span>ravel(), yy<span style="color:#f92672">.</span>ravel()]
probs <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict(grid)[:,<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>reshape(xx<span style="color:#f92672">.</span>shape)

f, ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">6</span>))
contour <span style="color:#f92672">=</span> ax<span style="color:#f92672">.</span>contourf(xx, yy, probs, <span style="color:#ae81ff">25</span>, cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;RdBu&#34;</span>,
                      vmin<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, vmax<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
ax_c <span style="color:#f92672">=</span> f<span style="color:#f92672">.</span>colorbar(contour)
ax_c<span style="color:#f92672">.</span>set_label(<span style="color:#e6db74">&#34;$P(y = 1)$&#34;</span>)
ax_c<span style="color:#f92672">.</span>set_ticks([<span style="color:#ae81ff">0</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">25</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">5</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">75</span>, <span style="color:#ae81ff">1</span>])

ax<span style="color:#f92672">.</span>scatter(X[:,<span style="color:#ae81ff">0</span>], X[:, <span style="color:#ae81ff">1</span>], c<span style="color:#f92672">=</span>y, s<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>,
           cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;RdBu&#34;</span>, vmin<span style="color:#f92672">=-.</span><span style="color:#ae81ff">2</span>, vmax<span style="color:#f92672">=</span><span style="color:#ae81ff">1.2</span>,
           edgecolor<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;white&#34;</span>, linewidth<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)

plt<span style="color:#f92672">.</span>show()

<span style="color:#75715e"># test accuracy</span>
<span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> accuracy_score
y_test_pred <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict(X_test)
test_accuracy <span style="color:#f92672">=</span> accuracy_score((y_test_pred <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0.5</span>), y_test)

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Test Accuracy = &#39;</span>, test_accuracy)

</code></pre></div><pre><code>Train on 1120 samples, validate on 280 samples
Epoch 1/50
1120/1120 [==============================] - 0s 96us/sample - loss: 0.7056 - acc: 0.4991 - val_loss: 0.7119 - val_acc: 0.4536
Epoch 2/50
1120/1120 [==============================] - 0s 20us/sample - loss: 0.7048 - acc: 0.5000 - val_loss: 0.7114 - val_acc: 0.4643
.
.
Epoch 49/50
1120/1120 [==============================] - 0s 19us/sample - loss: 0.6910 - acc: 0.6366 - val_loss: 0.6997 - val_acc: 0.5929
Epoch 50/50
1120/1120 [==============================] - 0s 22us/sample - loss: 0.6910 - acc: 0.6348 - val_loss: 0.6991 - val_acc: 0.5714
</code></pre>
<p><img src="../2_3/output_20_1.png" alt="png"></p>
<pre><code>Test Accuracy =  0.6633333333333333
</code></pre>
<h3 id="stochastic-gradient-descent-with-momentum">Stochastic gradient descent with momentum</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf
<span style="color:#f92672">from</span> tensorflow <span style="color:#f92672">import</span> keras
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>backend<span style="color:#f92672">.</span>clear_session()

<span style="color:#75715e"># random number initialized to same, for reproducing the same results.</span>
np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">0</span>)
tf<span style="color:#f92672">.</span>set_random_seed(<span style="color:#ae81ff">0</span>)

model <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>Sequential([
                             keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Dense(units<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>, input_shape<span style="color:#f92672">=</span>[<span style="color:#ae81ff">2</span>]), 
                             keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Activation(<span style="color:#e6db74">&#39;tanh&#39;</span>),
                             keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Dense(units<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>),
                             keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Activation(<span style="color:#e6db74">&#39;tanh&#39;</span>),
                             keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Dense(units<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>), 
                             keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Activation(<span style="color:#e6db74">&#39;sigmoid&#39;</span>)
                             ])

<span style="color:#75715e"># we used the default optimizer parameters by using optimizer=&#39;adam&#39;</span>
<span style="color:#75715e"># model.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])</span>

<span style="color:#75715e"># we can also define optimizer with</span>
optimizer <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>optimizers<span style="color:#f92672">.</span>SGD(lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.9</span>, nesterov<span style="color:#f92672">=</span>True)
model<span style="color:#f92672">.</span>compile(optimizer<span style="color:#f92672">=</span>optimizer, loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;binary_crossentropy&#39;</span>, metrics<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;accuracy&#39;</span>])
tf_history <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>fit(X_train, y_train, batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>, verbose<span style="color:#f92672">=</span>True, validation_data<span style="color:#f92672">=</span>(X_val, y_val))


<span style="color:#75715e"># contour plot</span>
xx, yy <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>mgrid[<span style="color:#f92672">-</span><span style="color:#ae81ff">1.5</span>:<span style="color:#ae81ff">1.5</span>:<span style="color:#f92672">.</span><span style="color:#ae81ff">01</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1.5</span>:<span style="color:#ae81ff">1.5</span>:<span style="color:#f92672">.</span><span style="color:#ae81ff">01</span>]
grid <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>c_[xx<span style="color:#f92672">.</span>ravel(), yy<span style="color:#f92672">.</span>ravel()]
probs <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict(grid)[:,<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>reshape(xx<span style="color:#f92672">.</span>shape)

f, ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">6</span>))
contour <span style="color:#f92672">=</span> ax<span style="color:#f92672">.</span>contourf(xx, yy, probs, <span style="color:#ae81ff">25</span>, cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;RdBu&#34;</span>,
                      vmin<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, vmax<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
ax_c <span style="color:#f92672">=</span> f<span style="color:#f92672">.</span>colorbar(contour)
ax_c<span style="color:#f92672">.</span>set_label(<span style="color:#e6db74">&#34;$P(y = 1)$&#34;</span>)
ax_c<span style="color:#f92672">.</span>set_ticks([<span style="color:#ae81ff">0</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">25</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">5</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">75</span>, <span style="color:#ae81ff">1</span>])

ax<span style="color:#f92672">.</span>scatter(X[:,<span style="color:#ae81ff">0</span>], X[:, <span style="color:#ae81ff">1</span>], c<span style="color:#f92672">=</span>y, s<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>,
           cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;RdBu&#34;</span>, vmin<span style="color:#f92672">=-.</span><span style="color:#ae81ff">2</span>, vmax<span style="color:#f92672">=</span><span style="color:#ae81ff">1.2</span>,
           edgecolor<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;white&#34;</span>, linewidth<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)

plt<span style="color:#f92672">.</span>show()

<span style="color:#75715e"># test accuracy</span>
<span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> accuracy_score
y_test_pred <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict(X_test)
test_accuracy <span style="color:#f92672">=</span> accuracy_score((y_test_pred <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0.5</span>), y_test)

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Test Accuracy = &#39;</span>, test_accuracy)

</code></pre></div><pre><code>Train on 1120 samples, validate on 280 samples
Epoch 1/50
1120/1120 [==============================] - 0s 104us/sample - loss: 0.7047 - acc: 0.5080 - val_loss: 0.7094 - val_acc: 0.4821
Epoch 2/50
1120/1120 [==============================] - 0s 20us/sample - loss: 0.7002 - acc: 0.5000 - val_loss: 0.7033 - val_acc: 0.4714
.
.
Epoch 49/50
1120/1120 [==============================] - 0s 20us/sample - loss: 0.6351 - acc: 0.7714 - val_loss: 0.6531 - val_acc: 0.7214
Epoch 50/50
1120/1120 [==============================] - 0s 21us/sample - loss: 0.6307 - acc: 0.7750 - val_loss: 0.6463 - val_acc: 0.7393
</code></pre>
<p><img src="../2_3/output_22_1.png" alt="png"></p>
<pre><code>Test Accuracy =  0.7866666666666666
</code></pre>
<p>You can note the difference, optimizer with momentum got accuracy of 0.78 in 50 epochs, whereas optimizer without momentum got 0.663 in 50 epochs</p>
<h2 id="adam-optimizer">Adam optimizer</h2>
<p><img src="https://www.math.purdue.edu/~nwinovic/figures/adam.png" alt="">
Check this <a href="https://arxiv.org/abs/1412.6980">paper</a> to know about adam.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf
<span style="color:#f92672">from</span> tensorflow <span style="color:#f92672">import</span> keras
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>backend<span style="color:#f92672">.</span>clear_session()

<span style="color:#75715e"># random number initialized to same, for reproducing the same results.</span>
np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">0</span>)
tf<span style="color:#f92672">.</span>set_random_seed(<span style="color:#ae81ff">0</span>)

model <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>Sequential([
                             keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Dense(units<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>, input_shape<span style="color:#f92672">=</span>[<span style="color:#ae81ff">2</span>]), 
                             keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Activation(<span style="color:#e6db74">&#39;tanh&#39;</span>),
                             keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Dense(units<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>),
                             keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Activation(<span style="color:#e6db74">&#39;tanh&#39;</span>),
                             keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Dense(units<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>), 
                             keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Activation(<span style="color:#e6db74">&#39;sigmoid&#39;</span>)
                             ])

<span style="color:#75715e"># we used the default optimizer parameters by using optimizer=&#39;adam&#39;</span>
<span style="color:#75715e"># model.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])</span>

<span style="color:#75715e"># we can also define optimizer with</span>
optimizer <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>optimizers<span style="color:#f92672">.</span>Adam(lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>)
model<span style="color:#f92672">.</span>compile(optimizer<span style="color:#f92672">=</span>optimizer, loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;binary_crossentropy&#39;</span>, metrics<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;accuracy&#39;</span>])
tf_history <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>fit(X_train, y_train, batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>, verbose<span style="color:#f92672">=</span>True, validation_data<span style="color:#f92672">=</span>(X_val, y_val))


<span style="color:#75715e"># contour plot</span>
xx, yy <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>mgrid[<span style="color:#f92672">-</span><span style="color:#ae81ff">1.5</span>:<span style="color:#ae81ff">1.5</span>:<span style="color:#f92672">.</span><span style="color:#ae81ff">01</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1.5</span>:<span style="color:#ae81ff">1.5</span>:<span style="color:#f92672">.</span><span style="color:#ae81ff">01</span>]
grid <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>c_[xx<span style="color:#f92672">.</span>ravel(), yy<span style="color:#f92672">.</span>ravel()]
probs <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict(grid)[:,<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>reshape(xx<span style="color:#f92672">.</span>shape)

f, ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">6</span>))
contour <span style="color:#f92672">=</span> ax<span style="color:#f92672">.</span>contourf(xx, yy, probs, <span style="color:#ae81ff">25</span>, cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;RdBu&#34;</span>,
                      vmin<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, vmax<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
ax_c <span style="color:#f92672">=</span> f<span style="color:#f92672">.</span>colorbar(contour)
ax_c<span style="color:#f92672">.</span>set_label(<span style="color:#e6db74">&#34;$P(y = 1)$&#34;</span>)
ax_c<span style="color:#f92672">.</span>set_ticks([<span style="color:#ae81ff">0</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">25</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">5</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">75</span>, <span style="color:#ae81ff">1</span>])

ax<span style="color:#f92672">.</span>scatter(X[:,<span style="color:#ae81ff">0</span>], X[:, <span style="color:#ae81ff">1</span>], c<span style="color:#f92672">=</span>y, s<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>,
           cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;RdBu&#34;</span>, vmin<span style="color:#f92672">=-.</span><span style="color:#ae81ff">2</span>, vmax<span style="color:#f92672">=</span><span style="color:#ae81ff">1.2</span>,
           edgecolor<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;white&#34;</span>, linewidth<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)

plt<span style="color:#f92672">.</span>show()

<span style="color:#75715e"># test accuracy</span>
<span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> accuracy_score
y_test_pred <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict(X_test)
test_accuracy <span style="color:#f92672">=</span> accuracy_score((y_test_pred <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0.5</span>), y_test)

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Test Accuracy = &#39;</span>, test_accuracy)

</code></pre></div><pre><code>Train on 1120 samples, validate on 280 samples
Epoch 1/50
1120/1120 [==============================] - 0s 120us/sample - loss: 0.6971 - acc: 0.5080 - val_loss: 0.6996 - val_acc: 0.6036
Epoch 2/50
1120/1120 [==============================] - 0s 24us/sample - loss: 0.6908 - acc: 0.5545 - val_loss: 0.6979 - val_acc: 0.5357
.
.
Epoch 49/50
1120/1120 [==============================] - 0s 33us/sample - loss: 0.0785 - acc: 0.9804 - val_loss: 0.0694 - val_acc: 0.9821
Epoch 50/50
1120/1120 [==============================] - 0s 25us/sample - loss: 0.0748 - acc: 0.9804 - val_loss: 0.0729 - val_acc: 0.9786
</code></pre>
<p><img src="../2_3/output_25_1.png" alt="png"></p>
<pre><code>Test Accuracy =  0.9833333333333333
</code></pre>
<p>Adam was able to give an accuracy of 0.98 in the same 50 epochs.</p>
<p>So Optimization algorithms affect the learning performance a lot. A good(right) optimization algorithm can improve your performance a lot.</p>
<p>Check out the other optimizers in Tensorflow in the docs.</p>

          </div>

          



          
          <div class="article-widget">
            
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/courses/deeplearning/2.2/" rel="next">Batch Training</a>
  </div>
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/courses/deeplearning/2.4/" rel="prev">Learning Rate</a>
  </div>
  
</div>

          </div>
          
        </div>

        
<section id="comments">
  <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "shangeth-com" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


        
        <div class="body-footer">
          Last updated on Sep 3, 2019
        </div>

      </article>

      <footer class="site-footer">
  

  <p class="powered-by">
    © 2020 Shangeth Rajaa &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
  </p>
</footer>


    </main>
  </div>
</div>

    

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    

    
    
    
    <script id="dsq-count-scr" src="//shangeth-com.disqus.com/count.js" async></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js" integrity="sha256-pB/deHc9CGfFpJRjC43imB29Rse8tak+5eXqntO94ck=" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.ee8463f2a394889d45e169a983fe913d.js"></script>

  </body>
</html>


