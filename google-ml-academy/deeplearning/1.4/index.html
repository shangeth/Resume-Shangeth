<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.3.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Shangeth Rajaa">

  
  
  
    
  
  <meta name="description" content="Open in GitHub
Google ML Academy 2019 Instructor: Shangeth Rajaa 
Solutions Here: 
 Open in GitHub
Multi Class Classification In the previous notebeook we used logistic regression for Binary Classification, now we will see how to train a classifier model for Multi-Class Classification.
What is Multi-Class Classification? If the target values have n discrete classification classes ie: y can take discrete value from 0 to n-1.">

  
  <link rel="alternate" hreflang="en-us" href="/google-ml-academy/deeplearning/1.4/">

  


  

  

  

  

  

  

  
  
  
  <meta name="theme-color" content="hsl(339, 90%, 68%)">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light" disabled>
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark">
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.26264af3549d61c0ce873bd043df951e.css">

  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-134441268-1', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/google-ml-academy/deeplearning/1.4/">

  
  
  
  
    
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@shangethr">
  <meta property="twitter:creator" content="@shangethr">
  
  <meta property="og:site_name" content="Shangeth">
  <meta property="og:url" content="/google-ml-academy/deeplearning/1.4/">
  <meta property="og:title" content=" | Shangeth">
  <meta property="og:description" content="Open in GitHub
Google ML Academy 2019 Instructor: Shangeth Rajaa 
Solutions Here: 
 Open in GitHub
Multi Class Classification In the previous notebeook we used logistic regression for Binary Classification, now we will see how to train a classifier model for Multi-Class Classification.
What is Multi-Class Classification? If the target values have n discrete classification classes ie: y can take discrete value from 0 to n-1."><meta property="og:image" content="/img/instructor.jpeg">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2019-08-30T00:00:00&#43;01:00">
  
  <meta property="article:modified_time" content="2019-08-30T00:00:00&#43;01:00">
  

  

  

  <title> | Shangeth</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" class="dark">
  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Shangeth</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#featured">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link  active" href="/google-ml-academy/">
            
            <span>Google ML Academy</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>



<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      




<form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-3" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <span><i class="fas fa-bars"></i></span>
  </button>

  
  <input name="q" type="search" class="form-control" id="search-query" placeholder="Search..." autocomplete="off">
  
</form>

<nav class="collapse docs-links" id="docs-nav">
  
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/google-ml-academy/deeplearning/">Course Overview</a>

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/google-ml-academy/deeplearning/1.1/">1.Intro to Deep Learning</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/google-ml-academy/deeplearning/1.1/">1.1.Linear Regression</a>
      </li>
      
      <li >
        <a href="/google-ml-academy/deeplearning/1.2/">1.2.Assignment - Polynomial Regression</a>
      </li>
      
      <li >
        <a href="/google-ml-academy/deeplearning/1.3/">1.3.Logistic Regression</a>
      </li>
      
      <li class="active">
        <a href="/google-ml-academy/deeplearning/1.4/">1.4.Assignment - Multiclass Classification</a>
      </li>
      
    </ul>
    

  </div>
  
  
</nav>

    </div>

    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      
      <p class="docs-toc-title">On this page</p>
      

      <nav id="TableOfContents">
<ul>
<li><a href="#multi-class-classification">Multi Class Classification</a>
<ul>
<li><a href="#what-is-multi-class-classification">What is Multi-Class Classification?</a></li>
</ul></li>
<li><a href="#task-1">Task - 1</a>
<ul>
<li><a href="#visualizing-data">Visualizing Data</a></li>
</ul></li>
<li><a href="#softmax-regression">Softmax Regression</a>
<ul>
<li><a href="#how-to-get-the-probabilities-softmax">How to get the probabilities? : SoftMax</a></li>
<li><a href="#loss-function">Loss Function</a></li>
<li><a href="#softmax-regression-model">Softmax Regression Model</a></li>
</ul></li>
<li><a href="#task-2">Task-2</a>
<ul>
<li><a href="#train-validation-test-split">Train-Validation-Test Split</a>
<ul>
<li><a href="#train-set">train set</a></li>
<li><a href="#validation-set">validation set</a></li>
<li><a href="#testing-set">testing set</a></li>
</ul></li>
<li><a href="#tensorflow-model">Tensorflow Model</a></li>
</ul></li>
</ul>
</nav>

      <ul class="nav toc-top">
        <li><a href="#">Back to top</a></li>
      </ul>

      
    </div>
    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article" itemscope itemtype="http://schema.org/Article">

        <div class="docs-article-container">
          <h1 itemprop="name"></h1>

          <div class="article-style" itemprop="articleBody">
            

<p><a href="https://colab.research.google.com/github/shangeth/Google-ML-Academy/blob/master/1-Intro-to-Deep-Learning/1_4_1_MultiClass_Classification.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>

<p><center><a href="https://github.com/shangeth/Google-ML-Academy/blob/master/1-Intro-to-Deep-Learning/1_4_1_MultiClass_Classification.ipynb" target="_parent"><svg class="octicon octicon-mark-github v-align-middle" height="30" viewBox="0 0 16 16" version="1.1" width="30" aria-hidden="true"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path></svg> Open in GitHub</a></center></p>

<p><center><h1><a href='https://shangeth.com/google-ml-academy/'>Google ML Academy 2019</a></h1></center>
<center><h3>Instructor: <a href='https://shangeth.com/'>Shangeth Rajaa</a></h3></center>
<hr></p>

<p>Solutions Here:
<a href="https://colab.research.google.com/github/shangeth/Google-ML-Academy/blob/master/1-Intro-to-Deep-Learning/1_4_2_MultiClass_Classification_Solution.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>

<p><center><a href="https://github.com/shangeth/Google-ML-Academy/blob/master/1-Intro-to-Deep-Learning/1_4_2_MultiClass_Classification_Solution.ipynb" target="_parent"><svg class="octicon octicon-mark-github v-align-middle" height="30" viewBox="0 0 16 16" version="1.1" width="30" aria-hidden="true"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path></svg> Open in GitHub</a></center></p>

<h1 id="multi-class-classification">Multi Class Classification</h1>

<p>In the previous notebeook we used logistic regression for Binary Classification, now we will see how to train a classifier model for Multi-Class Classification.</p>

<h2 id="what-is-multi-class-classification">What is Multi-Class Classification?</h2>

<p>If the target values have n discrete classification classes ie: y can take discrete value from 0 to n-1. If $y \in {0, 1, 2, 3, &hellip;, n-1}$, then the classification task is n-Multi-Class.</p>

<p><img src="https://miro.medium.com/max/972/1*SwXHlCzh-d9UqHOglp3vcA.png" alt="" /></p>

<h1 id="task-1">Task - 1</h1>

<h2 id="visualizing-data">Visualizing Data</h2>

<p>Create a 3-Multi-Class dataset with sklearn.datasets and visualize it.</p>

<p>It&rsquo;s very easy, use the same code form previous notebook and make changes for 3 classes.</p>

<pre><code class="language-python">from sklearn.datasets import make_blobs

X, y = make_blobs(n_samples=300, n_features=2, centers=3, random_state=42)

X.shape, y.shape, set(y)
</code></pre>

<pre><code>((300, 2), (300,), {0, 1, 2})
</code></pre>

<p>If you made 3 centers, you can see <code>set(y)</code> will return <code>{0, 1, 2}</code>. where 0 represent the first class, 1 represent second and 2 represents the third class.</p>

<pre><code class="language-python">import numpy as np

# getting the index of each class
class_0 = np.where(y == 0)
class_1 = np.where(y == 1)
class_2 = np.where(y == 2)

X_0 = X[class_0]
X_1 = X[class_1]
X_2 = X[class_2]

X_0.shape, X_1.shape, X_2.shape
</code></pre>

<pre><code>((100, 2), (100, 2), (100, 2))
</code></pre>

<pre><code class="language-python">import matplotlib.pyplot as plt


plt.figure(figsize=(12,9))
plt.scatter(X_0[:, 0], X_0[:, 1], marker='x', s=150, color='red', label='0')
plt.scatter(X_1[:, 0], X_1[:, 1], marker='o', s=150, color='blue', label='1')
plt.scatter(X_2[:, 0], X_2[:, 1], marker='s', s=150, color='red', label='2')
plt.xlabel('$x1$', fontsize=20)
plt.ylabel('$x2$', fontsize=20)
plt.grid(True)
plt.legend(fontsize=20)
plt.show()
</code></pre>

<p><img src="../1_4/output_7_0.png" alt="png" /></p>

<h1 id="softmax-regression">Softmax Regression</h1>

<h2 id="how-to-get-the-probabilities-softmax">How to get the probabilities? : SoftMax</h2>

<p>Now the target is going to be $y \in {0, 1, 2}$, so sigmoid cannot be used here, as sigmoid will convert any number to range 0 to 1 , so it can only be used for binary classification.</p>

<p>We need a function which converts the scores/logits of linear mapping into probabilities for all n classes.</p>

<p>That function should have some properties:</p>

<ul>
<li>all probabilities should be &gt;0</li>
<li>probabilities should be in range $[0,1]$</li>
<li>some of all class probabilities = 1</li>
</ul>

<p><br>
One possible function can be class_logit/sum of all class logits. Lets try it</p>

<p>Example:</p>

<p>$logits = [-100, 40, -10]$, right now don&rsquo;t bother how do we get 3 logits, we will discuss it below.</p>

<p>$probabilities = [\dfrac{-100}{(-100+40-10)}, \dfrac{40}{(-100+40-10)}, \dfrac{-10}{(-100+40-10)}]$</p>

<p>$probabilities = [\dfrac{100}{70}, \dfrac{-40}{70}, \dfrac{10}{70}]$</p>

<p>you can see this example satisfies only the third property(sum=1). So we need a function which gives positive numbers. Exponential function can help us.</p>

<p>$Logits = [l_0, l_1, l_2, &hellip;, l_{n-1}]$</p>

<p>$Probabilities = [\dfrac{e^{l_0}}{e^{l_1} + e^{l_2}+ &hellip; + e^{l_{n-1}}}, \dfrac{e^{l_1}}{e^{l_1} + e^{l_2}+ &hellip; + e^{l_{n-1}}}, &hellip;, \dfrac{e^{l_{n-1}}}{e^{l_1} + e^{l_2}+ &hellip; + e^{l_{n-1}}}]$</p>

<p>This function is called Softmax, and this gives the probability that a data belongs to class j, given the logits.</p>

<p>$P(y=j|z) = \dfrac{e^{z_j}}{\sum_{i=0}^{n-1}e^{z_i}}$</p>

<p>Let&rsquo;s code softmax function in Numpy.</p>

<pre><code class="language-python">import numpy as np

def softmax(x):
  exp = np.exp(x)
  exp_sum = exp.sum(axis=1).reshape(-1,1)
  return exp/exp_sum
</code></pre>

<pre><code class="language-python">x = np.array([[22, 40, 10]])

softmax(x)
</code></pre>

<pre><code>array([[1.52299795e-08, 9.99999985e-01, 9.35762283e-14]])
</code></pre>

<p>Now we know, replacing sigmoid with with softmax will help in the case of multi class classification. This softmax model is also called <strong>Softmax Regression</strong>.</p>

<h2 id="loss-function">Loss Function</h2>

<p>As we have already seen, for classification task we will use Cross Entropy loss.
The prediction of softmax regression $\hat{y} = [0.129, 0.8, 0.071]$, whereas the true label will be one of $y \in {0, 1, 2}$. We cannot directly use Cross Entropy loss with $\hat{y}$ and $y$.</p>

<p>So we convert the true label into One-Hot Encoding form. One hot encoding is a vector representation of the label which has &lsquo;1&rsquo; at the index corresponding to the label and &lsquo;0&rsquo; elsewhere.</p>

<p>Example:</p>

<p>Let $y \in {0, 1, 2, 3, 4}$, then</p>

<ul>
<li>&lsquo;4&rsquo; is represented as $[0, 0, 0, 0, 1]$</li>
<li>&lsquo;3&rsquo; is represented as $[0, 0, 0, 1, 0]$</li>
<li>&lsquo;2&rsquo; is represented as $[0, 0, 1, 0, 0]$</li>
<li>&lsquo;1&rsquo; is represented as $[0, 1, 0, 0, 0]$</li>
<li>&lsquo;0&rsquo; is represented as $[1, 0, 0, 0, 0]$</li>
</ul>

<p>Let&rsquo;s code the label to one hot conversion</p>

<pre><code class="language-python">import numpy as np

def to_one_hot(labels, num_classes):
    return np.eye(num_classes)[labels]

num_classes = 5
labels = np.array([0, 1, 2, 3, 4])

to_one_hot(labels, num_classes)
</code></pre>

<pre><code>array([[1., 0., 0., 0., 0.],
       [0., 1., 0., 0., 0.],
       [0., 0., 1., 0., 0.],
       [0., 0., 0., 1., 0.],
       [0., 0., 0., 0., 1.]])
</code></pre>

<p>You can also use sklearn.preprocessing.OneHotEncoder to convert labels to one hot vectors.</p>

<pre><code class="language-python">from sklearn.preprocessing import OneHotEncoder

labels = np.array([[0], 
                   [1], 
                   [2], 
                   [3], 
                   [4]])

OneHotEncoder(categories='auto').fit_transform(labels).toarray()
</code></pre>

<pre><code>array([[1., 0., 0., 0., 0.],
       [0., 1., 0., 0., 0.],
       [0., 0., 1., 0., 0.],
       [0., 0., 0., 1., 0.],
       [0., 0., 0., 0., 1.]])
</code></pre>

<p>Keras also have some utils functions which can help in one-hot encoding</p>

<pre><code class="language-python">from keras.utils.np_utils import to_categorical   

labels = np.array([0, 1, 2, 3, 4])
to_categorical(labels, num_classes=5)
</code></pre>

<pre><code>Using TensorFlow backend.

array([[1., 0., 0., 0., 0.],
       [0., 1., 0., 0., 0.],
       [0., 0., 1., 0., 0.],
       [0., 0., 0., 1., 0.],
       [0., 0., 0., 0., 1.]], dtype=float32)
</code></pre>

<h2 id="softmax-regression-model">Softmax Regression Model</h2>

<p>From what we discussed so far, if the number of classes = 3, then we expect model to give a prediction $\hat{y} = Softmax(z)$ and $z$ will be like $z = [-10, 20, 5]$(Example).</p>

<p>$z = X.W + b$ will only give one number like $z=[4]$ in logistic regression. But now we are using softmax regression which expect a model which gives 3 output for a 3 class classifier.</p>

<p>If the no of input features = 2 and no of out[ut classes = 3
So we will use 3 linear classifier.</p>

<p>$z_1 = X.W_1 + b_1$, $z_2 = X.W_2 + b_2$, $z_3 = X.W_3 + b_3$ which can be combined together with</p>

<p>z = $\begin{bmatrix}z_1&amp;z_2&amp;z_3\ \end{bmatrix}$</p>

<p>$ z = X . W + b $</p>

<p>$W = \begin{bmatrix}W_1&amp;W_2&amp;W_3\ \end{bmatrix} $</p>

<p>$b = \begin{bmatrix}b_1&amp;b_2&amp;b_3\ \end{bmatrix}$</p>

<p>each $W_i = \begin{bmatrix}W_{i1}\ W_{i2}\ W_{i3}\ \end{bmatrix} $</p>

<p>so the final $W = \begin{bmatrix}W_{11}&amp;W_{12}&amp;W_{13} \\ W_{21}&amp;W_{22}&amp;W_{23} \ \end{bmatrix}$</p>

<p><br><hr><br>
Let $X = \begin{bmatrix}x_1&amp;x_2\ \end{bmatrix}$</p>

<p>$z =\begin{bmatrix}z_1&amp;z_2&amp;z_3\ \end{bmatrix} = \begin{bmatrix}x_1&amp;x_2 \ \end{bmatrix} . \begin{bmatrix}W_{11}&amp;W_{12}&amp;W_{13} \\ W_{21}&amp;W_{22}&amp;W_{23} \\ \end{bmatrix} + \begin{bmatrix}b_1&amp;b_2&amp;b_3\ \end{bmatrix}$</p>

<p><br></p>

<ul>
<li>For 1 data, $(1,2).(2,3) + (1,3) = (1,3)$</li>
<li>For n data, $(n,2).(2,3) + (1,3) = (n,3)$, b will be added to all n data, this is called broadcasting.</li>
</ul>

<p><br>
Frameworks like Tensorflow, PyTorch will take care of this matrix form of $W$ and $b$ for you.</p>

<h1 id="task-2">Task-2</h1>

<p>Train a Softmax Regression with Tensorflow</p>

<pre><code class="language-python"># Data

from sklearn.datasets import make_blobs

X, y = make_blobs(n_samples=1000, n_features=2, centers=3, random_state=42)
X.shape, y.shape, set(y)
</code></pre>

<pre><code>((1000, 2), (1000,), {0, 1, 2})
</code></pre>

<p>We need to convert the labels into one hot vectors to train the model. Let&rsquo;s use keras to_categorical function</p>

<pre><code class="language-python">print(y.shape)

y = to_categorical(y, num_classes=3)
print(y.shape)
</code></pre>

<pre><code>(1000,)
(1000, 3)
</code></pre>

<h2 id="train-validation-test-split">Train-Validation-Test Split</h2>

<p>So far we had a dataset and we used it for training and checked the accuracy/loss to see the performance. But its not the right way to check the preformance of a model. Usually any dataset is split into 3 parts namely Train-Validation-Test.</p>

<h3 id="train-set">train set</h3>

<p>This dataset is used to train the model. If the training is good, metrics of this dataset will be always good. Almost 60-70% of dataset is given to training set.</p>

<h3 id="validation-set">validation set</h3>

<p>After every epoch(generally) of training, metrics of this dataset is checked to ensure, the model is also performing good on unseen data as much as it performs on the training dataset. If the model performs well on training dataset but not good on validation set, it means the model has a problem called &lsquo;Overfitting&rsquo; whcih we will look in more detail later. Some hyper parameters are adjusted to make the model perform well in validation set as well during training. 10-20% of data is given to validation set.</p>

<h3 id="testing-set">testing set</h3>

<p>After the training is over for n epochs, when the model performs good in both training and validation sets, a final check is done to see the performance of the model on new unseen dataset. 20-30% of data is given to Test set.</p>

<p>The percentage numbers depends on the total number of data we have access to, which you will understand as you work on more projects.</p>

<p>We can split the dataset into train-test using <code>sklearn.model_selection.train_test_split</code></p>

<pre><code class="language-python">from sklearn.model_selection import train_test_split

print(X.shape, y.shape)
# test_size is the percent of split 0.2 means 20% of data is for testset.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)
</code></pre>

<pre><code>(1000, 2) (1000, 3)
(800, 2) (200, 2) (800, 3) (200, 3)
</code></pre>

<h2 id="tensorflow-model">Tensorflow Model</h2>

<ul>
<li>Make a Dataset with 2 input features, 3 output classes</li>
<li>one hot encode y</li>
<li>Split Dataset into Train-Validation-Test</li>
<li>Train Model with Validation Dataset, check the <a href="https://keras.io/models/model/" target="_blank">docs</a> on how to use validation data.</li>
<li>predict X_test with the trained model, refer the docs(model.predict function)</li>
<li>convert the prediction of X_test and y_test from one-hot to labels using np.argmax(pred, axis=1)</li>
<li>use sklearn.metrics.accuracy_score on prediction of X_test and y_test to find the accuracy on Test set.</li>
</ul>

<pre><code class="language-python">import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
import numpy as np
from sklearn.datasets import make_blobs

# Make the Dataset
num_classes = 3
num_input_features = 2
X, y = make_blobs(n_samples=2000, n_features=num_input_features, centers=num_classes, random_state=42)

# to categorical
y = to_categorical(y, num_classes=num_classes)

# train-test split
# 20% of dataset to testset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)

# train-validation split
# 20% of trainset to valset
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True)

# Model
model = tf.keras.Sequential([keras.layers.Dense(units=num_classes, input_shape=[num_input_features]), keras.layers.Activation('softmax')])
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
tf_history = model.fit(X_train, y_train, epochs=30, verbose=True, validation_data=(X_val, y_val))

# Prediction for Test set with trained Model
from sklearn.metrics import accuracy_score
y_test_pred = model.predict(X_test)
test_accuracy = accuracy_score(np.argmax(y_test_pred, axis=1), np.argmax(y_test, axis=1))

print('\nTest Accuracy = ', test_accuracy)
</code></pre>

<pre><code>Train on 1280 samples, validate on 320 samples
Epoch 1/30
1280/1280 [==============================] - 0s 300us/sample - loss: 5.9285 - acc: 0.3305 - val_loss: 5.8832 - val_acc: 0.3281
Epoch 2/30
1280/1280 [==============================] - 0s 40us/sample - loss: 5.3884 - acc: 0.3305 - val_loss: 5.3271 - val_acc: 0.3281
.
.
Epoch 29/30
1280/1280 [==============================] - 0s 41us/sample - loss: 0.0755 - acc: 0.9969 - val_loss: 0.0691 - val_acc: 0.9969
Epoch 30/30
1280/1280 [==============================] - 0s 41us/sample - loss: 0.0699 - acc: 0.9969 - val_loss: 0.0637 - val_acc: 0.9969

Test Accuracy =  0.995
</code></pre>

<p>Train the model with different
- no of input features
- no of output classes
- no of data
- split of train-validation-test
- epochs</p>

          </div>

          



          
          <div class="article-widget">
            
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/google-ml-academy/deeplearning/1.3/" rel="next"></a>
  </div>
  
  
</div>

          </div>
          
        </div>

        
<section id="comments">
  <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "shangeth-com" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


        
        <div class="body-footer">
          Last updated on Aug 30, 2019
        </div>

      </article>

      <footer class="site-footer">
  

  <p class="powered-by">
    &copy; 2019 Shangeth Rajaa &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
  </p>
</footer>


    </main>
  </div>
</div>

    

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    

    
    
    
    <script id="dsq-count-scr" src="//shangeth-com.disqus.com/count.js" async></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js" integrity="sha256-pB/deHc9CGfFpJRjC43imB29Rse8tak+5eXqntO94ck=" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.3258b3a711acd6208568ec000de4beec.js"></script>

  </body>
</html>


