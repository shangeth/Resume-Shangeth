<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Course Overview on Shangeth</title>
    <link>/google-ml-academy/deeplearning/</link>
    <description>Recent content in Course Overview on Shangeth</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; {year} Shangeth Rajaa</copyright>
    <lastBuildDate>Thu, 29 Aug 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/google-ml-academy/deeplearning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Linear Regression</title>
      <link>/google-ml-academy/deeplearning/1.1/</link>
      <pubDate>Thu, 29 Aug 2019 00:00:00 +0100</pubDate>
      
      <guid>/google-ml-academy/deeplearning/1.1/</guid>
      <description>Open in GitHub
Google ML Academy 2019 Instructor: Shangeth Rajaa 
Before starting with Neural Networks, we will look into 2 important machine learning models to understand regression and classification tasks - Linear Regression (Regression) - Logistic Regression (Classification)

Most of the Deep learning Courses do not start with linear regression(LinReg), but LinReg gave me a better understanding of machine learning, so i will start with that, hoping that will make the understanding of Neural networks easier.</description>
    </item>
    
    <item>
      <title>Polynomial Regression</title>
      <link>/google-ml-academy/deeplearning/1.2/</link>
      <pubDate>Thu, 29 Aug 2019 00:00:00 +0100</pubDate>
      
      <guid>/google-ml-academy/deeplearning/1.2/</guid>
      <description>Open in GitHub
Google ML Academy 2019 Instructor: Shangeth Rajaa 
Solutions Here:

 Open in GitHub
Its a very simple assignment, you can finish it in less than 10 minutes. If you are stuck somewhere refer this for solutions.
Task-1 : Linear Regression on Non-Linear Data  Get X and y from dataset() function Train a Linear Regression model for this dataset. Visualize the model prediction  Dataset Call dataset() function to get X, y</description>
    </item>
    
    <item>
      <title>Logistic Regression</title>
      <link>/google-ml-academy/deeplearning/1.3/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0100</pubDate>
      
      <guid>/google-ml-academy/deeplearning/1.3/</guid>
      <description>Open in GitHub
Google ML Academy 2019 Instructor: Shangeth Rajaa 
Logistic Regression is one of the most commonly used classification model. Unlike Linear Regression which predicts a real unbounded value $\hat{y} = f(X) = WX+b$, Logistic Regression predicts the probability of a data belonging to a particular class.

For example for a given data (X,y) where X is a recieved email and y is 0 if email is spam and 1 if email is not spam.</description>
    </item>
    
    <item>
      <title>Multi Class Classification</title>
      <link>/google-ml-academy/deeplearning/1.4/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0100</pubDate>
      
      <guid>/google-ml-academy/deeplearning/1.4/</guid>
      <description>Open in GitHub
Google ML Academy 2019 Instructor: Shangeth Rajaa 
Solutions Here: 
 Open in GitHub
In the previous notebeook we used logistic regression for Binary Classification, now we will see how to train a classifier model for Multi-Class Classification.
What is Multi-Class Classification? If the target values have n discrete classification classes ie: y can take discrete value from 0 to n-1. If $y \in {0, 1, 2, 3, &amp;hellip;, n-1}$, then the classification task is n-Multi-Class.</description>
    </item>
    
    <item>
      <title>Motivation for Multi Layer Perceptron</title>
      <link>/google-ml-academy/deeplearning/1.5/</link>
      <pubDate>Sun, 01 Sep 2019 00:00:00 +0100</pubDate>
      
      <guid>/google-ml-academy/deeplearning/1.5/</guid>
      <description>Open in GitHub
Google ML Academy 2019 Instructor: Shangeth Rajaa 
Non-Linearity Note: We will look mostly at classification examples, but the same concepts apply to regression problems as well with a little change in using activation function(Sigmoid, Softmax which we learned in previous sections).
So far the datasets we have used are linearly seperable, which means they can be seperated by line(2-d), plane(3-d) and linear multi dimensional classifiers.</description>
    </item>
    
    <item>
      <title>Architectures, Training of Neural Networks</title>
      <link>/google-ml-academy/deeplearning/2.1/</link>
      <pubDate>Mon, 02 Sep 2019 00:00:00 +0100</pubDate>
      
      <guid>/google-ml-academy/deeplearning/2.1/</guid>
      <description>Google ML Academy 2019 Instructor: Shangeth Rajaa 
Neural Network Architectures We trained our first neural network in the previous notebook which had 3 layers - Input Layer - Hidden Layer - Output Layer
Multiple Nodes The network had 2 linear layers($C_1$,0 $C_2$) in the hidden layer each of which gave us a linear classifier, then we used another linear layer($C_3$) in the output layer to combine $C_1$ and $C_2$ to give us a non-linear classifier($C$).</description>
    </item>
    
  </channel>
</rss>