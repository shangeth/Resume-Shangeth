---
title: 'GAN 2'
subtitle: 'Theory of Game between Generator and Discriminator'
summary: 'Theory of Game between Generator and Discriminator'
authors: 
- admin
tags:
- Academic- ## Supervised learning
categories: ['Deep Learning', 'Python', 'PyTorch']
date: "2019-05-20T02:43:00Z"
lastmod: ""
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal point options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
image:
  caption: 'Image credit: [**Gimages**](https://unsplash.com/photos/CpkOjOcXdUY)'
  focal_point: ""
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []


---

As we saw in [Intro and application of Generative Adversarial Network](https://shangeth.github.io/post/gan-1/), GANs generate new data from a given dataset by learning the distribution of the dataset through adverserial process.

## What is an adversarial process/learning?
A google search can tell you that adversarial machine learning is a technique used in Machine Learning which tries to fool the model by giving in false/malicious input.

## Components of GANs:
![](https://i.stack.imgur.com/UnKny.png)

- ### Generator
	The Generator network takes random noise as input and convert it to a data sample(image/music) . The output of generator is a fake but realistic data sample. The choice of the random noise determines the distribution into which the data sample generated falls.\\
	But the generator network have to be trained to produce samples for the given random noise. ie: the generator have to learn the distribution of the dataset, so it generates new data samples from the distribution.

	As this is not a supervised learning, we cannot use labels to learn the parameters of generator. So we use adversarial learning technique to learn the distribution of the dataset.

	The idea is to maximize the probability that the data sample generated by the generator is from the training dataset. But it is not easy as its un labelled , so we use the help of another network called Discriminator.

- ### Discriminator
	Discriminator is a normal Neural Network classifier. The discriminator finds if a data sample is from the training dataset or not.\\
	During the training process, the discriminator is given data from the training dataset 50% of the time and data samples generated by generator other 50% of the time. The discriminator classifies the generated data samples as fake and data from the training dataset as real data.

## The Game Theory
As the disciminator classifies the data sample from the generator as fake, the generator tries to fool the discriminator by generating more realistic data sample(learns the traning data distribution well). The generator starts generating samples more close to the distribution of the training dataset.

![](https://cs.stanford.edu/people/karpathy/gan/gan.png)

As the generator tries to fool the discriminator, the discriminator learns to classify the more realistic(fake) data generated by the generator as fake.//
By this process both the netowrks learn the parameters which gives best results. This creates a competition between Generator(G) and Discriminator(D), this makes this an adverserial learning.

[Check this](https://cs.stanford.edu/people/karpathy/gan/)